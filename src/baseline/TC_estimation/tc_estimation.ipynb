{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Total Correlation Estimation\n",
    "\n",
    "In this experiment, we evaluate performance of our Line-like and Tree-like total correlation (TC) estimators based on different mutual information (MI) estimators. \n",
    "First, we draw samples from multivariate Gaussian and Cubic distributions with the true TC values pre-known. Then we compare different MI estimators on estimating MI values based on the generated samples. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "#import os\n",
    "#os.environ['CUDA_VISIBLE_DEVICES'] = '1'\n",
    "\n",
    "#torch.backends.cudnn.enabled = True\n",
    "#torch.backends.cudnn.benchmark = True\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "To obtain multivariate samples with known TC values, we follow the sampler we used for MI estimation soiluation (check the details at https://github.com/Linear95/CLUB/mi_estimation.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_correlated_gaussian(rho=0.5, dim=20, sample_size=128, cubic = False):\n",
    "    \"\"\"Generate samples from a correlated Gaussian distribution.\"\"\"\n",
    "    mean = [0,0]\n",
    "    cov = [[1.0, rho],[rho, 1.0]]\n",
    "    x, y = np.random.multivariate_normal(mean, cov, sample_size * dim).T\n",
    "\n",
    "    x = x.reshape(-1, dim)\n",
    "    y = y.reshape(-1, dim)\n",
    "\n",
    "    if cubic:\n",
    "        y = y ** 3\n",
    "\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With above defined two-variable sampler, we build two new samplers for three variables and four variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def triple_correlated_gaussian(rho, dim, which_dim, batch_size, to_cuda, cubic=False):\n",
    "    '''\n",
    "    jointly sample data for three variables\n",
    "    rho : is the correlation coefficient\n",
    "    which_dim: determine which dim to be independent to the others\n",
    "    '''\n",
    "    x1, x2 = sample_correlated_gaussian(rho, dim, batch_size, to_cuda=False, cubic=False)\n",
    "    x3 = np.random.normal(size=(batch_size, dim))\n",
    "    if which_dim == 0:\n",
    "        outputs = np.stack([x3,x1,x2], axis = 1)\n",
    "    elif which_dim == 1:\n",
    "        outputs = np.stack([x1,x3,x2], axis = 1)\n",
    "    elif which_dim == 2:\n",
    "        outputs = np.stack([x1,x2,x3], axis = 1)\n",
    "    if to_cuda:\n",
    "        outputs = torch.from_numpy(outputs).float().cuda()\n",
    "\n",
    "    return outputs\n",
    "\n",
    "def four_correlated_gaussian(rho, dim, which_dim, batch_size, to_cuda, cubic=False):\n",
    "    '''\n",
    "    jointly sample data for four variables\n",
    "    rho : is the correlation coefficient\n",
    "    which_dim: determine which dim to be independent to the others\n",
    "    '''\n",
    "    x1, x2 = sample_correlated_gaussian(rho, dim, batch_size, to_cuda=False, cubic=False)\n",
    "    x3 = np.random.normal(size=(batch_size, dim))\n",
    "    x4 = np.random.normal(size=(batch_size, dim))\n",
    "    if which_dim == 0:\n",
    "        outputs = np.stack([x3,x1,x2,x4], axis = 1)\n",
    "    elif which_dim == 1:\n",
    "        outputs = np.stack([x1,x3,x2,x4], axis = 1)\n",
    "    elif which_dim == 2:\n",
    "        outputs = np.stack([x1,x2,x3,x4], axis = 1)\n",
    "    if to_cuda:\n",
    "        outputs = torch.from_numpy(outputs).float().cuda()\n",
    "\n",
    "    return outputs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Under the Gaussian distribution, the correlation coefficient and mutual information have [one-to-one](https://en.wikipedia.org/wiki/Mutual_information#Linear_correlation) mapping:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rho_to_mi(rho, dim):\n",
    "    result = -dim / 2 * np.log(1 - rho **2)\n",
    "    return result\n",
    "\n",
    "def mi_to_rho(mi, dim):\n",
    "    result = np.sqrt(1 - np.exp(-2 * mi / dim))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_multivariate_gaussian_given_TC(tc_value, var_num, sample_size=128, dim=10, cubic=False):\n",
    "    '''\n",
    "    return np array with shape [sample_size, var_num, dim]\n",
    "    '''\n",
    "    if var_num < 1:\n",
    "        print(\"ERROR: number of variable cannot be smaller than 1.\")\n",
    "    elif var_num == 1:\n",
    "        return np.random.normal(size=(sample_size, 1, dim))\n",
    "    elif var_num == 2:\n",
    "        rho = mi_to_rho(tc_value, dim)\n",
    "        \n",
    "        mean = [0,0]\n",
    "        cov = [[1.0, rho],[rho, 1.0]]\n",
    "        x, y = np.random.multivariate_normal(mean, cov, sample_size * dim).T\n",
    "\n",
    "        x = x.reshape(-1, 1, dim)\n",
    "        y = y.reshape(-1, 1, dim)\n",
    "            \n",
    "        return np.concatenate([x,y], axis=1)\n",
    "    elif var_num == 3:\n",
    "        x = sample_multivariate_gaussian_given_TC(0., 1, sample_size=sample_size, dim=dim, cubic=cubic)\n",
    "        y = sample_multivariate_gaussian_given_TC(tc_value, 2, sample_size=sample_size, dim=dim, cubic=cubic)\n",
    "        return np.concatenate([x,y], axis=1)\n",
    "    \n",
    "    else:\n",
    "        left_var_num = var_num//2\n",
    "        right_var_num = var_num - left_var_num\n",
    "        x = sample_multivariate_gaussian_given_TC(tc_value/2., left_var_num, sample_size=sample_size, dim=dim, cubic=cubic)\n",
    "        y = sample_multivariate_gaussian_given_TC(tc_value/2., right_var_num, sample_size=sample_size, dim=dim, cubic=cubic)\n",
    "        return np.concatenate([x,y], axis=1)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tc_estimators import TCLineEstimator, TCTreeEstimator\n",
    "\n",
    "sample_dim = 20\n",
    "batch_size = 64\n",
    "hidden_size = 15\n",
    "learning_rate = 0.001\n",
    "training_steps = 4000\n",
    "\n",
    "var_num = 4\n",
    "cubic = False \n",
    "\n",
    "model_list = [\"MINE\",\"NWJ\",\"InfoNCE\", \"CLUB\"]\n",
    "\n",
    "tc_value_list = [2.0, 4.0, 6.0, 8.0, 10.0]\n",
    "\n",
    "total_steps = training_steps*len(tc_value_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train different TC estimators with samples drawn from different Gaussian distributions with different TC true values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train Tree-like TC estimators with samples \n",
    "\n",
    "tree_results = dict()\n",
    "for i, model_name in enumerate(model_list):\n",
    "    \n",
    "    model = TCTreeEstimator(\n",
    "        dims=[sample_dim for _ in range(var_num)], \n",
    "        hidden_size=hidden_size, \n",
    "        mi_estimator=model_name\n",
    "    )\n",
    "    model = model.to(device)\n",
    "    \n",
    "    optimizer = torch.optim.Adam(model.parameters(), learning_rate)\n",
    "\n",
    "    tc_est_values = []\n",
    "    start_time = time.time()\n",
    "    for i, tc_value in enumerate(tc_value_list):\n",
    "        rho = mi_to_rho(tc_value, sample_dim)\n",
    "\n",
    "        for step in range(training_steps):\n",
    "            #batch_x, batch_y = sample_correlated_gaussian(rho, dim=sample_dim, batch_size = batch_size, to_cuda = True, cubic = cubic)\n",
    "            #samples = four_correlated_gaussian(rho, dim=sample_dim, which_dim=1, batch_size=batch_size, to_cuda=True, cubic=False)\n",
    "            samples = sample_multivariate_gaussian_given_TC(tc_value, var_num=var_num, sample_size=batch_size, dim=sample_dim, cubic=cubic)\n",
    "            #samples = torch.tensor(samples).float().to(device)\n",
    "            samples = [torch.tensor(samples[:,i]).float().to(device) for i in range(var_num)]\n",
    "            model.eval()\n",
    "            #samples = torch.stack([batch_x, batch_y], dim=1) #[batch,2,dim]\n",
    "            tc_est_values.append(model(samples).item())\n",
    "            \n",
    "            model.train() \n",
    "            model_loss = model.learning_loss(samples)\n",
    "           \n",
    "            optimizer.zero_grad()\n",
    "            model_loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            del samples\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "        print(\"finish training for %s with true TC value = %f\" % (model.__class__.__name__, tc_value))\n",
    "        # torch.save(model.state_dict(), \"./model/%s_%d.pt\" % (model.__class__.__name__, int(mi_value)))\n",
    "        torch.cuda.empty_cache()\n",
    "    end_time = time.time()\n",
    "    time_cost = end_time - start_time\n",
    "    print(\"model %s average time cost is %f s\" % (model_name, time_cost/total_steps))\n",
    "    tree_results[model_name] = tc_est_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# train Line-like TC estimators with samples \n",
    "\n",
    "line_results = dict()\n",
    "for i, model_name in enumerate(model_list):\n",
    "    \n",
    "    model = TCLineEstimator(\n",
    "        dims=[sample_dim for _ in range(var_num)], \n",
    "        hidden_size=hidden_size, \n",
    "        mi_estimator=model_name\n",
    "    )\n",
    "    model = model.to(device)\n",
    "    \n",
    "    optimizer = torch.optim.Adam(model.parameters(), learning_rate)\n",
    "\n",
    "    tc_est_values = []\n",
    "    start_time = time.time()\n",
    "    for i, tc_value in enumerate(tc_value_list):\n",
    "        rho = mi_to_rho(tc_value, sample_dim)\n",
    "\n",
    "        for step in range(training_steps):\n",
    "            #batch_x, batch_y = sample_correlated_gaussian(rho, dim=sample_dim, batch_size = batch_size, to_cuda = True, cubic = cubic)\n",
    "            #samples = four_correlated_gaussian(rho, dim=sample_dim, which_dim=1, batch_size=batch_size, to_cuda=True, cubic=False)\n",
    "            samples = sample_multivariate_gaussian_given_TC(tc_value, var_num=var_num, sample_size=batch_size, dim=sample_dim, cubic=cubic)\n",
    "            #samples = torch.tensor(samples).float().to(device)\n",
    "            samples = [torch.tensor(samples[:,i]).float().to(device) for i in range(var_num)]\n",
    "            model.eval()\n",
    "            #samples = torch.stack([batch_x, batch_y], dim=1) #[batch,2,dim]\n",
    "            tc_est_values.append(model(samples).item())\n",
    "            \n",
    "            model.train() \n",
    "            model_loss = model.learning_loss(samples)\n",
    "           \n",
    "            optimizer.zero_grad()\n",
    "            model_loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            del samples\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "        print(\"finish training for %s with true TC value = %f\" % (model.__class__.__name__, tc_value))\n",
    "        # torch.save(model.state_dict(), \"./model/%s_%d.pt\" % (model.__class__.__name__, int(mi_value)))\n",
    "        torch.cuda.empty_cache()\n",
    "    end_time = time.time()\n",
    "    time_cost = end_time - start_time\n",
    "    print(\"model %s average time cost is %f s\" % (model_name, time_cost/total_steps))\n",
    "    line_results[model_name] = tc_est_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Save estimation results.\n",
    "# import pickle\n",
    "\n",
    "# with open('results/line_results.p', 'wb') as f:\n",
    "#     pickle.dump(line_results, f)\n",
    "    \n",
    "# with open('results/tree_results.p', 'wb') as f:\n",
    "#     pickle.dump(tree_results, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "colors = sns.color_palette()\n",
    "\n",
    "EMA_SPAN = 200\n",
    "\n",
    "model_list = [\"MINE\",\"NWJ\",\"InfoNCE\", \"CLUB\"]\n",
    "\n",
    "ncols = len(model_list)\n",
    "nrows = 1\n",
    "fig, axs = plt.subplots(nrows, ncols, figsize=(3.1 *ncols , 3.4 * nrows))\n",
    "axs = np.ravel(axs)\n",
    "\n",
    "\n",
    "xaxis = np.array(list(range(total_steps)))\n",
    "yaxis_mi = np.repeat(tc_value_list, training_steps)\n",
    "\n",
    "for i, model_name in enumerate(model_list):\n",
    "    plt.sca(axs[i])\n",
    "    p1 = plt.plot(line_results[model_name], alpha=0.4, color=colors[0])[0]  #color = 5 or 0\n",
    "    p2 = plt.plot(tree_results[model_name], alpha=0.4, color=colors[1])[0]  #color = 5 or 0\n",
    "    mis_smooth1 = pd.Series(line_results[model_name]).ewm(span=EMA_SPAN).mean()\n",
    "    mis_smooth2 = pd.Series(tree_results[model_name]).ewm(span=EMA_SPAN).mean()\n",
    "    \n",
    "    if i == 0:\n",
    "        plt.plot(mis_smooth1, c=p1.get_color(), label='Line est.')\n",
    "        plt.plot(mis_smooth2, c=p2.get_color(), label='Tree est.')\n",
    "        plt.plot(yaxis_mi, color='k', label='True TC')\n",
    "        plt.xlabel('Steps', fontsize= 14)\n",
    "        plt.ylabel('Total Correlation', fontsize = 14)\n",
    "        plt.legend(loc='upper left', prop={'size':15})\n",
    "    else:\n",
    "        plt.plot(mis_smooth1, c=p1.get_color())\n",
    "        plt.plot(mis_smooth2, c=p2.get_color())\n",
    "        plt.yticks([])\n",
    "        plt.plot(yaxis_mi, color='k')\n",
    "        plt.xticks([])\n",
    "    \n",
    "    plt.ylim(0, 15.5)\n",
    "    plt.xlim(0, total_steps)   \n",
    "    plt.title('TC-'+model_name, fontsize=15)\n",
    "    #plt.subplots_adjust( )\n",
    "\n",
    "plt.gcf().tight_layout()\n",
    "#plt.savefig('mi_est_Gaussian.pdf', bbox_inches=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the bias, variance and mean-squared-error (MSE) of the estimated TC to the true TC values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bias_dict = dict()\n",
    "var_dict = dict()\n",
    "mse_dict = dict()\n",
    "for i, model_name in enumerate(model_list):\n",
    "    bias_list = []\n",
    "    var_list = []\n",
    "    mse_list = []\n",
    "    for j, tc_v in enumerate(tc_value_list):\n",
    "        tc_est_vals = line_results[model_name][training_steps*(j+1)- 500:training_steps*(j+1)]\n",
    "        est_mean = np.mean(tc_est_vals)\n",
    "        bias_list.append(np.abs(tc_v - est_mean))\n",
    "        var_list.append(np.var(tc_est_vals))\n",
    "        mse_list.append(bias_list[j]**2+ var_list[j])\n",
    "    bias_dict[model_name] = bias_list\n",
    "    var_dict[model_name] = var_list\n",
    "    mse_dict[model_name] = mse_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('default')#('seaborn-notebook')\n",
    "\n",
    "colors = list(plt.rcParams['axes.prop_cycle'])\n",
    "col_idx = [2,4,5,1,3,0]\n",
    "\n",
    "ncols = 1\n",
    "nrows = 3\n",
    "fig, axs = plt.subplots(nrows, ncols, figsize=(4.5 * ncols, 3. * nrows))\n",
    "axs = np.ravel(axs)\n",
    "\n",
    "for i, model_name in enumerate(model_list):\n",
    "    plt.sca(axs[0])\n",
    "    plt.plot(tc_value_list, bias_dict[model_name], label='TC-'+model_name, marker='d', color = colors[col_idx[i]][\"color\"]) \n",
    "    \n",
    "    plt.sca(axs[1])\n",
    "    plt.plot(tc_value_list, var_dict[model_name], label='TC-'+model_name, marker='d', color = colors[col_idx[i]][\"color\"]) \n",
    "    \n",
    "    plt.sca(axs[2])\n",
    "    plt.plot(tc_value_list, mse_dict[model_name], label='TC-'+model_name, marker='d', color = colors[col_idx[i]][\"color\"]) \n",
    "        \n",
    "ylabels = ['Bias', 'Variance', 'MSE']\n",
    "for i in range(3):\n",
    "    plt.sca(axs[i])\n",
    "    plt.ylabel(ylabels[i], fontsize=15)\n",
    "    \n",
    "    if i == 0:\n",
    "        if cubic:\n",
    "            plt.title('Cubic', fontsize=17)\n",
    "        else:\n",
    "            plt.title('Gaussian', fontsize=17)\n",
    "    if i == 1:\n",
    "        plt.yscale('log')\n",
    "    if i == 2:\n",
    "        plt.legend(loc='upper left', prop={'size': 12})\n",
    "        plt.xlabel('TC-Line Est. Values',fontsize=15)\n",
    "        \n",
    "plt.gcf().tight_layout()\n",
    "#plt.savefig('bias_variance_Gaussian.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bias_dict = dict()\n",
    "var_dict = dict()\n",
    "mse_dict = dict()\n",
    "for i, model_name in enumerate(model_list):\n",
    "    bias_list = []\n",
    "    var_list = []\n",
    "    mse_list = []\n",
    "    for j, tc_v in enumerate(tc_value_list):\n",
    "        tc_est_vals = tree_results[model_name][training_steps*(j+1)- 500:training_steps*(j+1)]\n",
    "        est_mean = np.mean(tc_est_vals)\n",
    "        bias_list.append(np.abs(tc_v - est_mean))\n",
    "        var_list.append(np.var(tc_est_vals))\n",
    "        mse_list.append(bias_list[j]**2+ var_list[j])\n",
    "    bias_dict[model_name] = bias_list\n",
    "    var_dict[model_name] = var_list\n",
    "    mse_dict[model_name] = mse_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('default')#('seaborn-notebook')\n",
    "\n",
    "colors = list(plt.rcParams['axes.prop_cycle'])\n",
    "col_idx = [2,4,5,1,3,0]\n",
    "\n",
    "ncols = 1\n",
    "nrows = 3\n",
    "fig, axs = plt.subplots(nrows, ncols, figsize=(4.5 * ncols, 3. * nrows))\n",
    "axs = np.ravel(axs)\n",
    "\n",
    "for i, model_name in enumerate(model_list):\n",
    "    plt.sca(axs[0])\n",
    "    plt.plot(tc_value_list, bias_dict[model_name], label='TC-'+model_name, marker='d', color = colors[col_idx[i]][\"color\"]) \n",
    "    \n",
    "    plt.sca(axs[1])\n",
    "    plt.plot(tc_value_list, var_dict[model_name], label='TC-'+model_name, marker='d', color = colors[col_idx[i]][\"color\"]) \n",
    "    \n",
    "    plt.sca(axs[2])\n",
    "    plt.plot(tc_value_list, mse_dict[model_name], label='TC-'+model_name, marker='d', color = colors[col_idx[i]][\"color\"]) \n",
    "        \n",
    "ylabels = ['Bias', 'Variance', 'MSE']\n",
    "for i in range(3):\n",
    "    plt.sca(axs[i])\n",
    "    plt.ylabel(ylabels[i], fontsize=15)\n",
    "    \n",
    "    if i == 0:\n",
    "        if cubic:\n",
    "            plt.title('Cubic', fontsize=17)\n",
    "        else:\n",
    "            plt.title('Gaussian', fontsize=17)\n",
    "    if i == 1:\n",
    "        plt.yscale('log')\n",
    "    if i == 2:\n",
    "        plt.legend(loc='upper left', prop={'size': 12})\n",
    "        plt.xlabel('TC Tree Est. Values',fontsize=15)\n",
    "        \n",
    "plt.gcf().tight_layout()\n",
    "#plt.savefig('bias_variance_Gaussian.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
