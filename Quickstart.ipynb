{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from experiments.config import get_default_config\n",
    "from src.benchmark.synthetic_dataset import  get_task,get_dataloader\n",
    "from src.libs.soi import  SOI\n",
    "from src.libs.soi_grad import  SOI_grad\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Default config\n",
    "args=get_default_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Redundancy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.14736860225060955"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Make a synthetic task with 6 made of two redundant subtasks of 3 variables.\n",
    "my_settings = [{\"rho\":0.6,\"type\":\"red\",\"nb\":3} ]\n",
    "args.dim = 1\n",
    "task_red = get_task(args,my_settings)\n",
    "task_red.o_inf()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Synergy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.12391808195228782"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Make a synthetic task with 6 made of two redundant subtasks of 3 variables.\n",
    "my_settings = [{\"rho\":0.6,\"type\":\"syn\",\"nb\":3} ]\n",
    "args.dim = 1\n",
    "task_syn = get_task(args,my_settings)\n",
    "task_syn.get_summary()[\"o_inf\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Redundancy + Synergy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.02345052029832928"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Make a synthetic task with 6 made of two redundant subtasks of 3 variables.\n",
    "my_settings = [{\"rho\":0.6,\"type\":\"red\",\"nb\":3},{\"rho\":0.6,\"type\":\"syn\",\"nb\":3} ]\n",
    "args.dim = 1\n",
    "task_both = get_task(args,my_settings)\n",
    "task_both.get_summary()[\"o_inf\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# O-information estimation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "args.use_ema=True\n",
    "args.weight_s_functions = True\n",
    "args.importance_sampling = True\n",
    "args.bs = 512\n",
    "args.warmup_epochs = 30\n",
    "args.max_epochs = 50\n",
    "args.test_epoch = 5\n",
    "args.debug = True\n",
    "args.ou_dir = \"quickstart/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Runing SOI "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### On the redundancy benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weighting the scores to learn \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA A100-SXM4-80GB') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "\n",
      "  | Name      | Type | Params\n",
      "-----------------------------------\n",
      "0 | score     | DiT  | 623 K \n",
      "1 | model_ema | EMA  | 623 K \n",
      "-----------------------------------\n",
      "1.2 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.2 M     Total params\n",
      "4.984     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |                                                    | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22c61b6a978d44439a66a4f76dc66f59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |                                                           | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  35  GT:  0.147 SOI_estimate:  0.143\n",
      "Epoch:  40  GT:  0.147 SOI_estimate:  0.146\n",
      "Epoch:  45  GT:  0.147 SOI_estimate:  0.143\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                         | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SOI: {' O-inf': 0.1467235326766968, 'tc': 0.4903195172548294, 'dtc': 0.3435959845781326, 'S-info': 0.833915501832962}\n",
      "GT: {' O-inf': 0.14736860225060955, 'tc': 0.5220620516920196, 'dtc': 0.37469344944141003, 'S-info': 0.8967555011334296}\n"
     ]
    }
   ],
   "source": [
    "gt = task_red.get_summary()\n",
    "train_l, test_l  = get_dataloader(task_red,args)\n",
    "## Run SOI\n",
    "soi = SOI(args, nb_var = task_red.nb_var, gt = gt)\n",
    "## Fit the model\n",
    "soi.fit(train_l, test_l)\n",
    "## Compute O_information using the test_loader\n",
    "results = soi.compute_o_inf()\n",
    "print(\"SOI:\", {\" O-inf\": results[\"o_inf\"],\"tc\":results[\"tc\"], \"dtc\":results[\"dtc\"], \"S-info\": results[\"s_inf\"] })\n",
    "print(\"GT:\", {\" O-inf\": gt[\"o_inf\"],\"tc\":gt[\"tc\"], \"dtc\":gt[\"dtc\"], \"S-info\": gt[\"s_inf\"] } )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### On the synergy benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weighting the scores to learn \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "\n",
      "  | Name      | Type | Params\n",
      "-----------------------------------\n",
      "0 | score     | DiT  | 623 K \n",
      "1 | model_ema | EMA  | 623 K \n",
      "-----------------------------------\n",
      "1.2 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.2 M     Total params\n",
      "4.984     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |                                                    | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85289ec9a8994c61ab84d3b8b3de8f0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |                                                           | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  35  GT:  -0.124 SOI_estimate:  -0.125\n",
      "Epoch:  40  GT:  -0.124 SOI_estimate:  -0.126\n",
      "Epoch:  45  GT:  -0.124 SOI_estimate:  -0.11\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                         | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SOI: {' O-inf': -0.14697401523590087, 'tc': 0.49834243655204774, 'dtc': 0.6453164517879486, 'S-info': 1.1436588883399963}\n",
      "GT: {' O-inf': -0.12391808195228782, 'tc': 0.5697171415941797, 'dtc': 0.6936352235464676, 'S-info': 1.2633523651406473}\n"
     ]
    }
   ],
   "source": [
    "gt = task_syn.get_summary()\n",
    "train_l, test_l  = get_dataloader(task_syn,args)\n",
    "## Run SOI\n",
    "soi = SOI(args, nb_var = task_syn.nb_var, gt = gt)\n",
    "## Fit the model\n",
    "soi.fit(train_l, test_l)\n",
    "## Compute O_information using the test_loader\n",
    "results = soi.compute_o_inf()\n",
    "print(\"SOI:\", {\" O-inf\": results[\"o_inf\"],\"tc\":results[\"tc\"], \"dtc\":results[\"dtc\"], \"S-info\": results[\"s_inf\"] })\n",
    "print(\"GT:\", {\" O-inf\": gt[\"o_inf\"],\"tc\":gt[\"tc\"], \"dtc\":gt[\"dtc\"], \"S-info\": gt[\"s_inf\"] } )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### On the mixed benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weighting the scores to learn \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "\n",
      "  | Name      | Type | Params\n",
      "-----------------------------------\n",
      "0 | score     | DiT  | 624 K \n",
      "1 | model_ema | EMA  | 624 K \n",
      "-----------------------------------\n",
      "1.2 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.2 M     Total params\n",
      "4.993     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |                                                    | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01dc40c18a144035861c637f7fa35b48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |                                                           | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                         | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  65  GT:  0.023 SOI_estimate:  0.056\n",
      "Epoch:  70  GT:  0.023 SOI_estimate:  0.03\n",
      "Epoch:  75  GT:  0.023 SOI_estimate:  0.071\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SOI: {' O-inf': 0.04701898694038398, 'tc': 1.0358725666999817, 'dtc': 0.9888535797595978, 'S-info': 2.0247261464595794}\n",
      "GT: {' O-inf': 0.02345052029832928, 'tc': 1.0917791932861967, 'dtc': 1.0683286729878674, 'S-info': 2.160107866274064}\n"
     ]
    }
   ],
   "source": [
    "gt = task_both.get_summary()\n",
    "train_l, test_l  = get_dataloader(task_both,args)\n",
    "## Run SOI\n",
    "args.warmup_epochs = 60\n",
    "args.max_epochs = 80\n",
    "\n",
    "soi = SOI(args, nb_var = task_both.nb_var, gt = gt)\n",
    "## Fit the model\n",
    "soi.fit(train_l, test_l)\n",
    "## Compute O_information using the test_loader\n",
    "results = soi.compute_o_inf()\n",
    "print(\"SOI:\", {\" O-inf\": results[\"o_inf\"],\"tc\":results[\"tc\"], \"dtc\":results[\"dtc\"], \"S-info\": results[\"s_inf\"] })\n",
    "print(\"GT:\", {\" O-inf\": gt[\"o_inf\"],\"tc\":gt[\"tc\"], \"dtc\":gt[\"dtc\"], \"S-info\": gt[\"s_inf\"] } )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradients of O-information estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "g_o_ing :  x0: 0.147, x1: 0.147, x2: 0.147, x3: -0.124, x4: -0.124, x5: -0.124,\n"
     ]
    }
   ],
   "source": [
    "gt = task_both.get_summary()\n",
    "print(\"g_o_ing : \",\" \".join([ \"x{}: {},\".format(i,np.round(x,decimals=3) ) for i,x in enumerate(gt[\"g_o_inf\"]) ]) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weighting the scores to learn \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA A100-SXM4-80GB') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "\n",
      "  | Name      | Type | Params\n",
      "-----------------------------------\n",
      "0 | score     | DiT  | 624 K \n",
      "1 | model_ema | EMA  | 624 K \n",
      "-----------------------------------\n",
      "1.2 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.2 M     Total params\n",
      "4.993     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |                                                    | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a72b8456444405084df12cc4db3cb36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |                                                           | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                         | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O_inf - GT:  0.023 O_inf - SOI_new:  0.044\n",
      "Gradient O_inf - GT:  x0: 0.147, x1: 0.147, x2: 0.147, x3: -0.124, x4: -0.124, x5: -0.124,\n",
      "Gradient O_inf - SOI: x0: 0.146, x1: 0.153, x2: 0.133, x3: -0.125, x4: -0.095, x5: -0.168,\n",
      "O_inf - GT:  0.023 O_inf - SOI_new:  0.041\n",
      "Gradient O_inf - GT:  x0: 0.147, x1: 0.147, x2: 0.147, x3: -0.124, x4: -0.124, x5: -0.124,\n",
      "Gradient O_inf - SOI: x0: 0.132, x1: 0.14, x2: 0.135, x3: -0.119, x4: -0.089, x5: -0.156,\n",
      "O_inf - GT:  0.023 O_inf - SOI_new:  0.018\n",
      "Gradient O_inf - GT:  x0: 0.147, x1: 0.147, x2: 0.147, x3: -0.124, x4: -0.124, x5: -0.124,\n",
      "Gradient O_inf - SOI: x0: 0.143, x1: 0.124, x2: 0.126, x3: -0.138, x4: -0.136, x5: -0.174,\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                         | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'tc': 1.01420716047287,\n",
       " 'dtc': 1.0057169377803803,\n",
       " 'o_inf': 0.008490222692489668,\n",
       " 's_inf': 2.0199240982532505,\n",
       " 'g_o_inf': {'x0': 0.13632701635360722,\n",
       "  'x1': 0.11200442314147951,\n",
       "  'x2': 0.11321437358856212,\n",
       "  'x3': -0.11913098394870753,\n",
       "  'x4': -0.1387510180473327,\n",
       "  'x5': -0.17350099682807918},\n",
       " 'tc_minus': {'x0': 0.6894628465175628,\n",
       "  'x1': 0.7175222396850586,\n",
       "  'x2': 0.7158963143825531,\n",
       "  'x3': 0.592874801158905,\n",
       "  'x4': 0.4880099058151245,\n",
       "  'x5': 0.8521396815776825},\n",
       " 'dtc_minus': {'x0': 0.8172996401786804,\n",
       "  'x1': 0.8210364401340484,\n",
       "  'x2': 0.8206204652786255,\n",
       "  'x3': 0.4652535945177078,\n",
       "  'x4': 0.3407686650753021,\n",
       "  'x5': 0.6701484620571136}}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Run SOI with gradient of o-information estimation\n",
    "args.warmup_epochs = 80\n",
    "args.max_epochs = 100\n",
    "## Run SOI\n",
    "gt = task_both.get_summary()\n",
    "train_l, test_l  = get_dataloader(task_both,args)\n",
    "soi = SOI_grad(args, nb_var = task_both.nb_var, gt = task_both.get_summary())\n",
    "## Fit the model\n",
    "soi.fit(train_l, test_l)\n",
    "## Compute O_information using the test_loader\n",
    "print(\"The final estimation :\", soi.compute_o_inf_with_grad() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
