{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 33\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "33"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.SB.soi_grad import SOI\n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "from torch.utils.data import DataLoader\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "import numpy as np\n",
    "from src.benchmark.toy_dataset import Task_redundant ,Task_synergy,Task_combination\n",
    "from pytorch_lightning.trainer import seed_everything\n",
    "seed_everything(33)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_mod = 10\n",
    "dim=5\n",
    "r = {} \n",
    "\n",
    "def get_samples(test_loader,mod_list,device):\n",
    "        data ={ mod :torch.Tensor().to(device) for mod in mod_list} \n",
    "        for batch in test_loader:\n",
    "            for mod in mod_list:\n",
    "                data[mod]  = torch.cat([data[mod],batch[mod].to(device) ] )\n",
    "        return data\n",
    "    \n",
    "\n",
    "def test_sgima():\n",
    "    task = Task_combination(tasks= [Task_redundant(nb_var=3, rho=0.7 ,dim = dim),\n",
    "                                    Task_synergy(nb_var=3, rho=0.6,dim = dim),\n",
    "                                       Task_redundant(nb_var=3, rho=0.8,dim = dim),\n",
    "                               ]  ,dim=dim)\n",
    "    N =  1000 *100\n",
    "    nb_mod = task.nb_var\n",
    "    d_train, d_test = task.get_torch_dataset(N,10*1000,dim=dim,rescale=False)\n",
    "\n",
    "    train_loader = DataLoader(d_train, batch_size=256,shuffle=True,\n",
    "                                num_workers=8, drop_last=True)\n",
    "\n",
    "    test_loader = DataLoader(d_test, batch_size=1000,\n",
    "                                shuffle= False,\n",
    "                                num_workers=8, drop_last=False)\n",
    "\n",
    "    mod_list={ \"x\"+ str(i) : dim for i in range(nb_mod) }\n",
    "\n",
    "    test_samples = get_samples(test_loader, mod_list=mod_list,device = \"cuda\")\n",
    "\n",
    "    model = SOI(\n",
    "                    test_samples= test_samples,\n",
    "                    gt = task.get_summary(),\n",
    "                    lr=1e-3,\n",
    "                    mod_list =mod_list ,\n",
    "                    use_ema= True, \n",
    "                    debias=True,\n",
    "                    test_epoch= 10,\n",
    "                    scores_order= 2,\n",
    "                    debug= True,\n",
    "                    margin_time=1,\n",
    "                    tx=False,\n",
    "                    fill_zeros= True,\n",
    "                    weight_subsets=True )\n",
    "\n",
    "    CHECKPOINT_DIR = \"trained_models/\"\n",
    "    tb_logger =  TensorBoardLogger(save_dir = CHECKPOINT_DIR,name=\"test\"+str(dim))\n",
    "    trainer = pl.Trainer( logger= tb_logger,\n",
    "                        accelerator='gpu', devices= 1,\n",
    "                            max_epochs= 50, check_val_every_n_epoch=50,\n",
    "                            default_root_dir = CHECKPOINT_DIR,\n",
    "                        )\n",
    "\n",
    "    trainer.fit(model=model, train_dataloaders=train_loader,val_dataloaders=test_loader  )\n",
    "    return {\"gt\": task.get_summary(), \"soi\": model.compute_o_inf(test_samples, debias=True,nb_iter= 10)}\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting to sample data\n",
      "after cov\n",
      "after reshape\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA A100-SXM4-80GB') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "Missing logger folder: trained_models/test5\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "\n",
      "  | Name      | Type | Params\n",
      "-----------------------------------\n",
      "0 | score     | DiT  | 1.5 M \n",
      "1 | model_ema | EMA  | 1.5 M \n",
      "-----------------------------------\n",
      "3.0 M     Trainable params\n",
      "0         Non-trainable params\n",
      "3.0 M     Total params\n",
      "11.972    Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b796f5549e6b4bb1b1b39b017f631745",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ba9ead694e54c81a67f016d1833628b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O_inf -- GT: 2.6032749683598837   , e : -30.4765202999115\n",
      "Gradient O_inf -- GT: [1.2188919712334183, 1.2188919712334183, 1.2188919712334183, -0.6195904097613933, -0.6195904097613294, -0.6195904097613365, 2.0039734068880293, 2.0039734068880293, 2.0039734068880293]   , e : {'x0': {'simple': 0.6893796920776367}, 'x1': {'simple': 0.34291791915893555}, 'x2': {'simple': 0.2134089469909668}, 'x3': {'simple': 0.543980598449707}, 'x4': {'simple': 0.3030414581298828}, 'x5': {'simple': 0.3804740905761719}, 'x6': {'simple': 0.2804443836212158}, 'x7': {'simple': 0.4767894744873047}, 'x8': {'simple': 15.3138427734375}}\n",
      "O_inf -- GT: 2.6032749683598837   , e : -38.61995244026184\n",
      "Gradient O_inf -- GT: [1.2188919712334183, 1.2188919712334183, 1.2188919712334183, -0.6195904097613933, -0.6195904097613294, -0.6195904097613365, 2.0039734068880293, 2.0039734068880293, 2.0039734068880293]   , e : {'x0': {'simple': 0.9642848968505859}, 'x1': {'simple': 0.8795380592346191}, 'x2': {'simple': 0.6002116203308105}, 'x3': {'simple': 2.04559326171875}, 'x4': {'simple': 0.8782539367675781}, 'x5': {'simple': 1.0744895935058594}, 'x6': {'simple': 1.1123056411743164}, 'x7': {'simple': 1.3124322891235352}, 'x8': {'simple': 17.941604614257812}}\n",
      "O_inf -- GT: 2.6032749683598837   , e : -43.98494803905487\n",
      "Gradient O_inf -- GT: [1.2188919712334183, 1.2188919712334183, 1.2188919712334183, -0.6195904097613933, -0.6195904097613294, -0.6195904097613365, 2.0039734068880293, 2.0039734068880293, 2.0039734068880293]   , e : {'x0': {'simple': 1.1142768859863281}, 'x1': {'simple': 1.4127130508422852}, 'x2': {'simple': 1.2373838424682617}, 'x3': {'simple': 3.8911285400390625}, 'x4': {'simple': 1.635711669921875}, 'x5': {'simple': 1.2366352081298828}, 'x6': {'simple': 2.5796127319335938}, 'x7': {'simple': 1.8854866027832031}, 'x8': {'simple': 22.3255615234375}}\n"
     ]
    }
   ],
   "source": [
    "out = test_sgima()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
